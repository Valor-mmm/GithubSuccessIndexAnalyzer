{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Impact analysis of initial commits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/result.json'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-0162e3ab1d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimpact_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/final/api_result.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./data/final/Repo_Commits_JSON.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/GithubSuccessIndexAnalyzer/impact_analysis/prepare_data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_refurbish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0macquire_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/GithubSuccessIndexAnalyzer/data_refurbish/read_data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquire_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/result.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../impact_analysis/result_pickle.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/GithubSuccessIndexAnalyzer/data_refurbish/read_data.py\u001b[0m in \u001b[0;36macquire_dataframe\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0macquire_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../data/result.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mreduced_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/GithubSuccessIndexAnalyzer/data_refurbish/read_data.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjsonFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/result.json'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from impact_analysis.prepare_data import prepare_data\n",
    "\n",
    "df = prepare_data('./data/final/api_result.json', './data/final/Repo_Commits_JSON.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              stars      releases     forkCount    commitCount      watchers  \\\ncount  12716.000000  12716.000000  12716.000000   12716.000000  12716.000000   \nmean      37.833517      0.634869      9.310396    1693.293960      4.818968   \nstd      557.800379      4.974379    159.876539   22711.029629     41.620977   \nmin        0.000000      0.000000      0.000000       1.000000      0.000000   \n25%        0.000000      0.000000      0.000000       6.000000      1.000000   \n50%        0.000000      0.000000      0.000000      17.000000      1.000000   \n75%        2.000000      0.000000      1.000000      76.000000      2.000000   \nmax    33611.000000    245.000000  13395.000000  721223.000000   2351.000000   \n\n          diskUsage  \ncount  1.271600e+04  \nmean   1.412237e+04  \nstd    9.187170e+04  \nmin    0.000000e+00  \n25%    1.120000e+02  \n50%    2.440000e+02  \n75%    2.287750e+03  \nmax    3.705652e+06  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete forks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 11169 fork repositories.\nRepository is now of size: 1547\n"
     ]
    }
   ],
   "source": [
    "df_total: int = len(df.index)\n",
    "df = df[df['isFork']]\n",
    "df_no_fork: int = len(df.index)\n",
    "print('Removed ' + str(df_total - df_no_fork) + ' fork repositories.')\n",
    "print('Repository is now of size: ' + str(df_no_fork))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def success_formula(series):\n",
    "    active_timedelta = series.updatedAt - series.createdAt\n",
    "    commit_value = series.commitCount / 8\n",
    "    positive = series.stars + series.forkCount + series.watchers + active_timedelta.days + commit_value\n",
    "    timedelta = datetime.now() - series.updatedAt\n",
    "    value = positive / (timedelta.days + 1)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "\n",
    "def apply_formula(formula, name, dataframe):\n",
    "    new_row = {}\n",
    "    for index, row in dataframe.iterrows():\n",
    "        new_row[index] = formula(row)\n",
    "\n",
    "    dataframe[name] = Series(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_formula(success_formula, 'successIndex', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          nameWithOwner           createdAt           updatedAt  stars  \\\nPhE_dask       PhE/dask 2015-09-18 21:43:19 2016-02-11 18:22:48      0   \nccryx_i3       ccryx/i3 2015-12-07 10:58:23 2015-12-07 10:58:25      0   \nATamm_rmp     ATamm/rmp 2016-10-04 21:54:24 2016-11-17 00:22:53      0   \nNify_tidb     Nify/tidb 2017-03-14 11:45:36 2018-09-20 01:13:14      0   \nai5_apery     ai5/apery 2015-03-16 04:51:04 2017-11-13 07:08:12      1   \n\n           releases  isFork  forkCount  commitCount  \\\nPhE_dask          0    True          0         2693   \nccryx_i3          0    True          0         5296   \nATamm_rmp         0    True          0           92   \nNify_tidb         0    True          0         7297   \nai5_apery         6    True          0          403   \n\n                                                 description  watchers  \\\nPhE_dask   Task scheduling and blocked algorithms for par...         1   \nccryx_i3          A better tiling and dynamic window manager         1   \nATamm_rmp                         Remove my procrastination.         1   \nNify_tidb  TiDB is a distributed NewSQL database compatib...         1   \nai5_apery                                a USI Shogi engine.         2   \n\n           diskUsage  successIndex  \nPhE_dask        8197      0.480224  \nccryx_i3        8038      0.618470  \nATamm_rmp       2870      0.076446  \nNify_tidb      55444     27.168981  \nai5_apery       1062      2.811986  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Dataframe with Commit Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load\n",
    "\n",
    "with open('./data/14000Result.json') as f:\n",
    "    json_commit_msgs = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14861\n"
     ]
    }
   ],
   "source": [
    "commitDict = {}\n",
    "counter = 0\n",
    "\n",
    "for entry in json_commit_msgs:\n",
    "    repo_descriptor = entry['repoName'].partition('/')\n",
    "    owner = repo_descriptor[0].replace(r'\\W', '').replace(r'^\\d+', '')\n",
    "    name = repo_descriptor[2].replace(r'\\W', '')\n",
    "    owner_with_name = owner + '_' + name\n",
    "    commitDict[owner_with_name] = entry['message']\n",
    "    \n",
    "    if owner_with_name not in df.index:\n",
    "        counter += 1\n",
    "        \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "newColumn = Series(commitDict)\n",
    "df['initialCommitMessage'] = newColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          nameWithOwner           createdAt           updatedAt  stars  \\\nPhE_dask       PhE/dask 2015-09-18 21:43:19 2016-02-11 18:22:48      0   \nccryx_i3       ccryx/i3 2015-12-07 10:58:23 2015-12-07 10:58:25      0   \nATamm_rmp     ATamm/rmp 2016-10-04 21:54:24 2016-11-17 00:22:53      0   \nNify_tidb     Nify/tidb 2017-03-14 11:45:36 2018-09-20 01:13:14      0   \nai5_apery     ai5/apery 2015-03-16 04:51:04 2017-11-13 07:08:12      1   \n\n           releases  isFork  forkCount  commitCount  \\\nPhE_dask          0    True          0         2693   \nccryx_i3          0    True          0         5296   \nATamm_rmp         0    True          0           92   \nNify_tidb         0    True          0         7297   \nai5_apery         6    True          0          403   \n\n                                                 description  watchers  \\\nPhE_dask   Task scheduling and blocked algorithms for par...         1   \nccryx_i3          A better tiling and dynamic window manager         1   \nATamm_rmp                         Remove my procrastination.         1   \nNify_tidb  TiDB is a distributed NewSQL database compatib...         1   \nai5_apery                                a USI Shogi engine.         2   \n\n           diskUsage  successIndex  \\\nPhE_dask        8197      0.480224   \nccryx_i3        8038      0.618470   \nATamm_rmp       2870      0.076446   \nNify_tidb      55444     27.168981   \nai5_apery       1062      2.811986   \n\n                                        initialCommitMessage  \nPhE_dask                                   first commit -a\\n  \nccryx_i3                            Start tracking changes\\n  \nATamm_rmp  new additions to Focusing, Splash page and goa...  \nNify_tidb                                        Add files\\n  \nai5_apery                                 電王戦FINAL version\\n  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758\n1547\n"
     ]
    }
   ],
   "source": [
    "# df = df.dropna(how='any', axis=0)\n",
    "print(len(df[df.initialCommitMessage.notna()].index))\n",
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "conform_df = df[(df['initialCommitMessage'] == 'Initial commit')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataframe size: ' + str(len(df.index)))\n",
    "print('Conform df size: ' + str(len(conform_df.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
